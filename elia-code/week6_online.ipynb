{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visit http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "* Read about word2vec and download the Google pre-trained model binary\n",
    "\n",
    "**Required**:\n",
    "\n",
    "* For any selected title in your Webhose dataset (of size 10000), write a Python program than calculates 100 most similar titles from the remaining 9999:\n",
    "    * Calculate pairwise similarity using word2vec model\n",
    "    * Sort in reverse order to determine 100 titles with highest scores\n",
    "    * Print the selected title and those 100 similar titles\n",
    "* Review information about Apache Spark here\n",
    "* Review and download DataBricks Word2Vec Spark Training notebook here\n",
    "* Train word2vec model, based on the texts of the articles in your Webhose dataset, using Spark Word2Vec function\n",
    "\n",
    "Submission should consist of Jupyter Notebook file along with output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Google pre-trained model binary Word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import gensim, operator\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = '/home/elia/Dropbox/Harrisburg/ANLY_610/codes/models/wordvec/'\n",
    "data_path = '/home/elia/Dropbox/Harrisburg/ANLY_610/codes/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n",
      "Finished loading Word2Vec model...\n"
     ]
    }
   ],
   "source": [
    "def load_wordvec_model(modelName, modelFile, flagBin):\n",
    "    print('Loading ' + modelName + ' model...')\n",
    "    model = KeyedVectors.load_word2vec_format(model_path + modelFile, binary=flagBin)\n",
    "    print('Finished loading ' + modelName + ' model...')\n",
    "    return model\n",
    "\n",
    "model_word2vec = load_wordvec_model('Word2Vec', 'GoogleNews-vectors-negative300.bin.gz', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_webhouse_data(data_name): \n",
    "    data_file = data_path + data_name + '.json'\n",
    "    with open(data_file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        return data\n",
    "    \n",
    "data = load_webhouse_data('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_similarity(input1, input2, vectors):\n",
    "    term_vectors = [np.zeros(300), np.zeros(300)]\n",
    "    terms = [input1, input2]\n",
    "        \n",
    "    for index, term in enumerate(terms):\n",
    "        for i, t in enumerate(term.split(' ')):\n",
    "            try:\n",
    "                term_vectors[index] += vectors[t]\n",
    "            except:\n",
    "                term_vectors[index] += 0\n",
    "        \n",
    "    result = (1 - spatial.distance.cosine(term_vectors[0], term_vectors[1]))\n",
    "    if result is 'nan':\n",
    "        result = 0\n",
    "        \n",
    "    return result\n",
    "\n",
    "# function checks whether the input words are present in the vocabulary for the model\n",
    "def vocab_check(vectors, words):\n",
    "    \n",
    "    output = list()\n",
    "    for word in words:\n",
    "        if word in vectors.vocab:\n",
    "            output.append(word.strip())\n",
    "            \n",
    "    return output\n",
    "\n",
    "# function calculates similarity between two strings using a particular word vector model\n",
    "def calc_similarity(input1, input2, vectors):\n",
    "    s1words = set(vocab_check(vectors, input1.split()))\n",
    "    s2words = set(vocab_check(vectors, input2.split()))\n",
    "    if len(s1words) == 0 or len(s2words) == 0:\n",
    "        return 0 \n",
    "    output = vectors.n_similarity(s1words, s2words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 titles most similar to The Latest: President Trump signs Bibles at Alabama church\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "similarity | title \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "0.9999999  | üî• Trump just blurted out that Michael Cohen ‚Äúdirectly asked me for a pardon‚Äù ‚Äî thereby declaring himself a fact witness and fair game for deposition. Stable Genius Strikes Again.\n",
      "0.9999999  | üî• Trump calls Russia investigation a ‚Äòcollusion witch hoax‚Äô in rambling and inaccurate White House rant: he wrongly suggested the judge who sentenced Paul Manafort, to 47 months in jail had said ‚Äúthere was no collusion with Russia‚Äù.\n",
      "0.9999999  | üëâ Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | üëâ Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | üëâ Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | ‚ÄúWe Do Not Have Any Illusions on NKorea‚Äù\n",
      "0.9999999  | ‚ÄúTrump pressured aides to get security clearances for Ivanka, Kushner‚Äù\n",
      "0.9793438  | ‚ÄúTrump 2: People for Factories‚Äù Can‚Äôt Win an Election. So What Now? ‚Äì Daily Stormer\n",
      "0.9793438  | ‚ÄúScandalous‚Äù Ballot Harvesting Needs Federal Ban, Says RNC Member\n",
      "0.9793438  | ‚ÄúOh My God, Right At The President!‚Äù: SUV Almost Hits Trump‚Äôs Motorcade ‚Äì Real Conservatives Unite\n",
      "0.9782600  | ‚ÄúLights Out!‚Äù Did Trump and His Neocons Recycle Bush-Era Plan to Knock Out Venezuela‚Äôs Power Grid?\n",
      "0.9493324  | ‚ÄúI have a follow-up to my colleague‚Äôs question‚Äù ‚Äì finally, the White House press corps works together\n",
      "0.9493324  | ‚ÄúHe‚Äôs Just Not Worth It‚Äù Speaker Pelosi Comes Out Against Impeaching President Trump ‚Ä¶(For Now)\n",
      "0.9493324  | ‚ÄúGreat Progress in China Trade Talks‚Äù Happening\n",
      "0.9493324  | ‚ÄúFake Melania‚Äù Meme Is Causing The Internet To Lose Its Mind\n",
      "0.9493324  | ‚ÄúDemocrats don‚Äôt hate Jewish people, that‚Äôs silly!‚Äù ‚Äî Hack Acosta DEFENDS Democrats on anti-Semitism [VIDEO]\n",
      "0.9493324  | ‚ÄúChina Deal Would Mean Very Big Spike for Markets‚Äù\n",
      "0.9493324  | ‚ÄúAndrew McCabe‚Äù ‚Äì Google News: MILBANK: Trump hires only the worst people | Opinion ‚Äì Lockport Union-Sun & Journal\n",
      "0.9493324  | ‚ÄòYellow peril‚Äô: Here‚Äôs how blaming China for Fentanyl continues a racist legacy\n",
      "0.9493324  | ‚ÄòWhy would you lie about that?‚Äô: Trump is telling donors the ‚ÄòTim Apple‚Äô flub is ‚Äòfake news‚Äô ‚Äî despite video evidence\n",
      "0.9493324  | ‚ÄòWhy would you lie about that?‚Äô: Republican donors don‚Äôt understand why Trump would lie about ‚ÄòTim Apple‚Äô flub\n",
      "0.9493324  | ‚ÄòWe saw things that you wouldn‚Äôt believe‚Äô\n",
      "0.9493324  | ‚ÄòUnsustainable‚Äô: Here‚Äôs how Trump‚Äôs economic policies are floundering\n",
      "0.9493324  | ‚ÄòTrump just identified himself as a key witness‚Äô: How the president‚Äôs latest attack on Cohen could backfire legally\n",
      "0.9493324  | ‚ÄòTrump isn‚Äôt a vessel for God‚Äôs will‚Äô: Bill Maher destroys Evangelicals for believing the president is just like King Cyrus\n",
      "0.9493324  | ‚ÄòTrump is a cancer on the country,‚Äô House Dem says\n",
      "0.9493324  | ‚ÄòTim Apple‚Äô gaffe was on purpose: Trump\n",
      "0.9493324  | ‚ÄòThere‚Äôs No Reason to Obsess‚Äô Over Budget Deficit, President Trump‚Äôs Top Economic Adviser Says\n",
      "0.9493324  | ‚ÄòThe Supreme Court disagrees‚Äô: Trump gets wrecked for saying border wall‚Äôs ‚Äòconstitutionality‚Äô doesn‚Äôt matter\n",
      "0.9493324  | ‚ÄòThe ISIS threat will remain,‚Äô John Bolton says\n",
      "0.9493324  | ‚ÄòThe Daily Show‚Äô as a news source?\n",
      "0.9493324  | ‚ÄòSocialism!‚Äô is the GOP rallying cry for 2020\n",
      "0.9493324  | ‚ÄòShadow Media‚Äôs‚Äô Dark Money Funded $2 Million To ‚ÄòInvestigate‚Äô Donald Trump\n",
      "0.9493324  | ‚ÄòSaturday Night Live‚Äô Ratings Slip With Host Idris Elba\n",
      "0.9493324  | ‚ÄòSaturday Night Live' takes on R. Kelly in cold open, giving Trump jokes a brief rest\n",
      "0.9493324  | ‚ÄòSNL‚Äôs‚Äô Pete Davidson on Michael Jackson and R. Kelly: ‚ÄòYou Just Have to Admit They‚Äôre Bad People‚Äô\n",
      "0.9493324  | ‚ÄòS.N.L.‚Äô: Idris Elba Hosts, and R. Kelly Gets Roasted - The New York Times\n",
      "0.9436951  | ‚ÄòS.N.L.‚Äô: Idris Elba Hosts, and R. Kelly Gets Roasted\n",
      "0.9115126  | ‚ÄòRub and Tug‚Äô: Woman Who Sold Access to Trump and Family Ran Florida Sex Spas\n",
      "0.8983159  | ‚ÄòRepugnant‚Äô: MSNBC‚Äôs Nicolle Wallace and panelists explain how Fox News ‚Äòinstructs‚Äô Trump\n",
      "0.8780873  | ‚ÄòPresident Trump tweeted about my football skills‚Äô\n",
      "0.8727726  | ‚ÄòPresident Trump tweeted about my football skills‚Äô\n",
      "0.8596358  | ‚ÄòPhony WWE-style posturing‚Äô: CNN boss branded hypocrite after calling Fox News ‚Äòpropaganda network‚Äô\n",
      "0.8433072  | ‚ÄòPatently false‚Äô: Sarah Sanders gets pummeled as she struggles to defend Trump‚Äôs claim that Democrats hate Jews\n",
      "0.8433072  | ‚ÄòNot productive anymore‚Äô: GOP strategist on partisan divide\n",
      "0.8433072  | ‚ÄòNot my fault‚Äô: Trump struggles to defend his record amid setbacks on immigration, trade, North Korea\n",
      "0.8368047  | ‚ÄòMy Dad‚Äôs Not a Racist‚Äô: Book Describes Ivanka Trump‚Äôs Defense After Charlottesville\n",
      "0.8368047  | ‚ÄòMy Dad's Not a Racist': Book Describes Ivanka Trump's Defense After Charlottesville\n",
      "0.8368047  | ‚ÄòMiami Herald‚Äô Reporters Investigate Ties Between Massage Parlor Owner, Trump\n",
      "0.8368047  | ‚ÄòI‚Äôm winning!‚Äô Trump attacks ‚ÄòWacky Nut Job‚Äô Ann Coulter for her border wall criticism\n",
      "0.8368047  | ‚ÄòI‚Äôm winning!‚Äô Trump attacks ‚ÄòWacky Nut Job‚Äô Ann Coulter for her border wall criticism\n",
      "0.8368047  | ‚ÄòI‚Äôm not for impeachment,‚Äô Pelosi says, potentially roiling fellow Democrats\n",
      "0.8264572  | ‚ÄòI‚Äôm not for impeachment,‚Äô Pelosi says, potentially roiling fellow Democrats\n",
      "0.8079037  | ‚ÄòIt‚Äôs on videotape‚Äô: MSNBC‚Äôs Morning Joe stunned by Trump's obvious lie about ‚ÄòTim Apple‚Äô\n",
      "0.8011519  | ‚ÄòIt would ultimately come down to the use of force‚Äô: What would happen if Trump refused to leave office after 2020 loss?\n",
      "0.8011519  | ‚ÄòIt would ultimately come down to the use of force‚Äô: What would happen if Trump refused to leave office after 2020 loss?\n",
      "0.8011519  | ‚ÄòIt has been proven‚Äô: Fox News host burns GOPer for claiming there was no ‚Äòwrongdoing‚Äô in 2016 election\n",
      "0.8011519  | ‚ÄòIt gets real personal, real fast‚Äô: Dems fear targeting Trump kids could backfire\n",
      "0.8011519  | ‚ÄòImpeach the Russian Asset‚Äô: Protesters taunt Trump with signs as he arrives at Mar-a-Lago\n",
      "0.8011519  | ‚ÄòImpeach the Russian Asset‚Äô: Protesters taunt Trump with signs as he arrives at Mar-a-Lago\n",
      "0.8011519  | ‚ÄòI'm not for impeachment,' Pelosi says, potentially roiling fellow Democrats\n",
      "0.8011519  | ‚ÄòHe‚Äôs just not worth it‚Äô: Pelosi says she opposes moving to impeach Trump\n",
      "0.8011519  | ‚ÄòHe‚Äôs just not worth it‚Äô: Pelosi says she opposes moving to impeach Trump\n",
      "0.8011519  | ‚ÄòHelp from Trump is a phone call away‚Äô- Chamisa\n",
      "0.8011519  | ‚ÄòHelp from Trump is a phone call away‚Äô- Chamisa\n",
      "0.8011519  | ‚ÄòHe said, he said‚Äô ‚Äî Who can you trust in Michael Cohen-Donald Trump saga?\n",
      "0.8011519  | ‚ÄòHe said, he said‚Äô ‚Äì Who can you trust in Cohen-Trump saga?\n",
      "0.8011519  | ‚ÄòHe said, he said‚Äô ‚Äì Who can you trust in Cohen-Trump saga?\n",
      "0.8011519  | ‚ÄòHanging‚Äôs too good‚Äô: Journalist explains why Dems should skip Trump impeachment ‚Äî and destroy him by other means\n",
      "0.8011519  | ‚ÄòHanging‚Äôs too good‚Äô: Journalist explains why Dems should skip Trump impeachment ‚Äî and destroy him another way\n",
      "0.8011519  | ‚ÄòHAIL SATAN‚Äô: Satanists Fight Trump, & Satanic Temple Founder Says He‚Äôs Comin‚Äô For All You Theocrats | Politics\n",
      "0.8011519  | ‚ÄòHAIL SATAN': Satanists Fight Trump, & Satanic Temple Founder Says He's Comin' For All You Theocrats\n",
      "0.8011519  | ‚ÄòFox News‚Äô Host Pete Hegseth Says His New Goal In Life Is To Have Donald Trump Sign His Bible\n",
      "0.8011519  | ‚ÄòFake Melania‚Äô conspiracy theory is back after Trumps visit Alabama\n",
      "0.7920104  | ‚ÄòFake Melania‚Äô Conspiracy Theory Takes Off on Twitter Again\n",
      "0.7916777  | ‚ÄòCrazy‚Äô: CNN conservative shoots down Trump‚Äôs budget GOP can‚Äôt even understand\n",
      "0.7894279  | ‚ÄòBetrayal‚Äô: Trump supporters furious with the president for backsliding on immigration policy with promises of more workers\n",
      "0.7894279  | ‚ÄòBefuddled Old Goofball‚Äô: Internet reacts to Trump‚Äôs ridiculous defense of ‚ÄòTim Apple‚Äô flub\n",
      "0.7894279  | ‚ÄòBefuddled Old Goofball‚Äô: Internet explodes in laughter over Trump‚Äôs ridiculous defense of ‚ÄòTim Apple‚Äô flub\n",
      "0.7894279  | ‚ÄòAbsurd‚Äô to say U.S. President Trump unreliable trade negotiator with China: White House\n",
      "0.7894279  | ‚ÄòAbsurd‚Äô to say Trump unreliable trade negotiator with China: White House\n",
      "0.7894279  | ‚ÄòAbsurd‚Äô to say Trump unreliable trade negotiator with China: White House\n",
      "0.7883771  | ‚ÄòAbsurd‚Äô to say Trump unreliable trade negotiator with China: White House\n",
      "0.7724894  | ‚ÄòAbsurd‚Äô to say Trump unreliable trade negotiator with China ‚Äì White House\n",
      "0.7689173  | ‚ÄòAbout as likely as Mexico paying for Trump‚Äôs wall‚Äô: Some experts say Elizabeth Warren‚Äôs plan to break up Big Tech will never happen\n",
      "0.7657953  | ‚ÄòAbout as likely as Mexico paying for Trump‚Äôs wall‚Äô: Some experts say Elizabeth Warren‚Äôs plan to break up Big Tech will never happen\n",
      "0.7565801  | ‚ÄòAbout as likely as Mexico paying for Trump‚Äôs wall‚Äô: Some experts say Elizabeth Warren‚Äôs plan to break up Big Tech will never happen\n",
      "0.7514790  | ‚ÄòAbout as likely as Mexico paying for Trump‚Äôs wall‚Äô: Some experts say Elizabeth Warren‚Äôs plan to break up Big Tech will never happen\n",
      "0.7486728  | Œ£ŒøœÖŒ∑Œ¥ŒØŒ±: ŒàŒ∫œÅŒ∑ŒæŒ∑ œÉŒµ Œ¨Œ¥ŒµŒπŒø ŒªŒµœâœÜŒøœÅŒµŒØŒø œÉœÑŒø Œ∫Œ≠ŒΩœÑœÅŒø œÑŒ∑œÇ Œ£œÑŒøŒ∫œáœåŒªŒºŒ∑œÇ - [Capital.gr]\n",
      "0.7486728  | Œ†ŒªŒÆœÅœâœÉŒµ œÑŒ∑ŒΩ ŒºŒ±œÜŒØŒ± Œ≥ŒπŒ± ŒΩŒ± œÉŒ∫ŒøœÑœéœÉŒøœÖŒΩ œÑŒøŒΩ ŒµœÅœâŒºŒ≠ŒΩŒø œÑŒ∑œÇ - Œ§ŒøŒΩ \"œÑœÉŒπŒºŒ≠ŒΩœÑœâœÉŒ±ŒΩ\" - [Pronews.gr]\n",
      "0.7439390  | ŒùŒ± Œ≥ŒπŒ±œÑŒØ Œ±œÖœÑœå œÑŒø ŒºŒ≠œÅŒøœÇ ŒøŒΩŒøŒºŒ¨Œ∂ŒµœÑŒ±Œπ \"œÄŒπœÉŒØŒΩŒ± œÑŒøœÖ Œ∏Œ±ŒΩŒ¨œÑŒøœÖ\" - [E-eidhseis.com]\n",
      "0.7439390  | ŒúŒµŒ≥Œ¨ŒªŒ∑ Œ≠Œ∫œÅŒ∑ŒæŒ∑ œÉœÑŒ∑ Œ£œÑŒøŒ∫œáœåŒªŒºŒ∑! Œ†œÖŒ∫ŒΩŒøŒØ Œ∫Œ±œÄŒΩŒøŒØ Œ∫Œ±ŒªœçœÄœÑŒøœÖŒΩ œÑŒ∑ŒΩ œÄœåŒªŒ∑! - [Newsit.gr]\n",
      "0.7402664  | ƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬îƒë¬ü¬§¬î ‚Äì Daily Stormer\n",
      "0.7353255  | trump budget discussion thread\n",
      "0.7202483  | storybreak stars\n",
      "0.7199541  | slams 'grandstanding' California governor on asylum shelters\n",
      "0.7199541  | pricey telling Trump\n",
      "0.7198457  | pre-order the Mueller Report @ Amazon\n",
      "0.7194962  | popcorn futures soar\n",
      "0.7191714  | political opinion of the day\n"
     ]
    }
   ],
   "source": [
    "def get_most_similar_titles(data, data_id, sim_tit_num=100): \n",
    "    if data_id >= len(data): \n",
    "        raise IOError('The id to select title should be between 0 and {}'.format(len(data)))\n",
    "    title = data[data_id]['title']        \n",
    "    comparison_matrix = np.array(\n",
    "        [[data[index]['title'], calc_similarity(title, data[index]['title'], model_word2vec)] \n",
    "         for index in range(len(data)) if index != data_id])\n",
    "    return np.sort(comparison_matrix, axis=0)[::-1][:100]\n",
    "\n",
    "title_id = 23\n",
    "print(\"100 titles most similar to {}\".format(data[title_id]['title']))\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "print(\"similarity | title \")\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "for line in get_most_similar_titles(data, title_id): \n",
    "    print(\"{0:.7f}\".format(float(line[1])) + \"  | {}\".format(str(line[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **pyspark section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext() \n",
    "config = sc.getConf()\n",
    "config.set('spark.cores.max','4')\n",
    "config.set('spark.executor.memory', '4G')\n",
    "config.set('spark.driver.maxResultSize', '4g')\n",
    "config.set('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')\n",
    "config.set('spark.kryoserializer.buffer.max', '256m')\n",
    "config.set(\"spark.driver.cores\", \"3\")\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext(conf = config) \n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "\n",
    "print(\"Using Apache Spark Version\", sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def cleanup_pretokenize(text):\n",
    "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.replace(\"'s\", \" \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.replace(\"'ve\", \" have \")\n",
    "    text = text.replace(\"'re\", \" are \")\n",
    "    text = text.replace(\"I'm\",\" I am \")\n",
    "    text = text.replace(\"you're\",\" you are \")\n",
    "    text = text.replace(\"You're\",\" You are \")\n",
    "    text = text.replace(\"-\",\" \")\n",
    "    text = text.replace(\"/\",\" \")\n",
    "    text = text.replace(\"(\",\" \")\n",
    "    text = text.replace(\")\",\" \")\n",
    "    text = text.replace(\"%\",\" percent \")\n",
    "    return text\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def text_cleanup(row):\n",
    "    desc = row[2].strip().lower()\n",
    "    #tokens = [w.lemma_ for w in nlp(cleanup_pretokenize(desc))]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if len(token) > 3]\n",
    "    tokens = [lmtzr.lemmatize(token,'v') for token in tokens]\n",
    "    row[2] = ' '.join(tokens)\n",
    "    return row\n",
    "\n",
    "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'tokens')\n",
    "swr = StopWordsRemover(inputCol = 'tokens', outputCol = 'tokens_sw_removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- crawled: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- locations: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |    |-- organizations: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |    |-- persons: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |-- external_links: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- highlightText: string (nullable = true)\n",
      " |-- highlightTitle: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- ord_in_thread: long (nullable = true)\n",
      " |-- published: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- thread: struct (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- domain_rank: long (nullable = true)\n",
      " |    |-- main_image: string (nullable = true)\n",
      " |    |-- participants_count: long (nullable = true)\n",
      " |    |-- performance_score: long (nullable = true)\n",
      " |    |-- published: string (nullable = true)\n",
      " |    |-- replies_count: long (nullable = true)\n",
      " |    |-- section_title: string (nullable = true)\n",
      " |    |-- site: string (nullable = true)\n",
      " |    |-- site_categories: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- site_full: string (nullable = true)\n",
      " |    |-- site_section: string (nullable = true)\n",
      " |    |-- site_type: string (nullable = true)\n",
      " |    |-- social: struct (nullable = true)\n",
      " |    |    |-- facebook: struct (nullable = true)\n",
      " |    |    |    |-- comments: long (nullable = true)\n",
      " |    |    |    |-- likes: long (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- gplus: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- linkedin: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- pinterest: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- stumbledupon: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- vk: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |-- spam_score: double (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- title_full: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- uuid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- uuid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load json \n",
    "def load_json_data(data_name): \n",
    "    data_file = data_path + data_name + '.json'\n",
    "    return sqlContext.read.json(data_file)\n",
    "\n",
    "data_df = load_json_data('trump')\n",
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|WASHINGTON (AP) -...|\n",
      "|Trump surveys Ala...|\n",
      "|The Beat with Ari...|\n",
      "|BEAUREGARD, Ala. ...|\n",
      "|Trump should reco...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|                text|              tokens|\n",
      "+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[washington, ap, ...|\n",
      "|Trump surveys Ala...|[trump, surveys, ...|\n",
      "|The Beat with Ari...|[the, beat, with,...|\n",
      "|BEAUREGARD, Ala. ...|[beauregard, ala,...|\n",
      "|Trump should reco...|[trump, should, r...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|   tokens_sw_removed|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[washington, ap, ...|[washington, ap, ...|\n",
      "|Trump surveys Ala...|[trump, surveys, ...|[trump, surveys, ...|\n",
      "|The Beat with Ari...|[the, beat, with,...|[beat, ari, john,...|\n",
      "|BEAUREGARD, Ala. ...|[beauregard, ala,...|[beauregard, ala,...|\n",
      "|Trump should reco...|[trump, should, r...|[trump, reconside...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df = data_df.select('text')\n",
    "text_df.show(5)\n",
    "df_tokens = regexTokenizer.transform(text_df)\n",
    "df_tokens.show(5)\n",
    "desc_swr = swr.transform(df_tokens)\n",
    "desc_swr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(vectorSize = 300, minCount = 5, inputCol = 'tokens_sw_removed', outputCol = 'wordvectors')\n",
    "model = word2vec.fit(desc_swr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|         wordvectors|\n",
      "+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[-0.0749518844910...|\n",
      "|Trump surveys Ala...|[-0.0200785594274...|\n",
      "|The Beat with Ari...|[-0.1803129903661...|\n",
      "|BEAUREGARD, Ala. ...|[-0.0259655292435...|\n",
      "|Trump should reco...|[-0.0499572096919...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordvectors = model.transform(desc_swr)\n",
    "text_desc = wordvectors.select('text','wordvectors')\n",
    "text_desc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|        word|         similarity|\n",
      "+------------+-------------------+\n",
      "|        mike| 0.5678425431251526|\n",
      "|  emphasised| 0.5327044725418091|\n",
      "|     hawkish| 0.4932403564453125|\n",
      "|     gokhale|0.47736334800720215|\n",
      "|      bolton|0.47003406286239624|\n",
      "|      echoed|0.45853370428085327|\n",
      "|       vijay| 0.4505883753299713|\n",
      "|     advisor| 0.4262145161628723|\n",
      "|   secretary| 0.4251237213611603|\n",
      "|      mullen|0.40693843364715576|\n",
      "|counterparts|0.40623241662979126|\n",
      "|  undermined|0.38990429043769836|\n",
      "|      scored| 0.3882525563240051|\n",
      "|  emphasized| 0.3881252706050873|\n",
      "|      yaqing| 0.3880544602870941|\n",
      "|     qureshi| 0.3836938738822937|\n",
      "|      biegun|  0.380886971950531|\n",
      "|        hale| 0.3719295263290405|\n",
      "|       pence|0.37069055438041687|\n",
      "| embarrassed|0.36694759130477905|\n",
      "+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synonyms = model.findSynonyms(\"pompeo\", 20)   \n",
    "synonyms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|index|                text|              tokens|   tokens_sw_removed|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    1|secretary of ener...|[secretary, of, e...|[secretary, energ...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEARCH_QUERY = \"secretary of energy in the Trump administration\"\n",
    "query_df  = sc.parallelize([(1,SEARCH_QUERY)]).toDF(['index', 'text'])\n",
    "query_tok = regexTokenizer.transform(query_df)\n",
    "query_swr = swr.transform(query_tok)\n",
    "query_swr.show()\n",
    "query_vec = model.transform(query_swr)\n",
    "query_vec = query_vec.select('wordvectors').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)\n",
    "chunk = text_desc.collect()\n",
    "sim_rdd = sc.parallelize((i[0], float(cossim(query_vec, i[1]))) for i in chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "|name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |similarity        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "|Murkowski Welcomes Intent to Nominate David Bernhardt to be Interior Secretary\n",
      "U.S. Sen. today issued the following statement after President Trump announced his intent to nominate David Bernhardt to be Secretary of the Department of the Interior (DOI).\n",
      "‚ÄúI strongly support David Bernhardt to serve as Secretary of the Interior. He is an excellent choice and has demonstrated he is more than capable of leading on a permanent basis. It is critical that our Interior Secretary understand Alaska and I have no doubt he will continue to be a strong partner for our state. I will schedule a hearing and seek to move his nomination forward as expeditiously as possible.‚Äù\n",
      "Bernhardt has served as Acting Interior Secretary since January 2019. On July 24, 2017, the Senate confirmed Bernhardt to serve as deputy secretary of DOI with bipartisan support.\n",
      "Murkowski is Resources.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0.538481548614037 |\n",
      "|Defense Department's Patrick Shanahan, before he was tapped by President Donald Trump to serve as the department's Acting Secretary More WASHINGTON ‚Äî The White House declined to comment Monday on whether acting Secretary of Defense Patrick Shanahan would be tapped later this week by President Donald Trump to take the top spot at the Pentagon.\n",
      "\"I'm not going to make any personnel announcements at this time,\" press secretary Sarah Huckabee Sanders told reporters Monday during a media briefing at the White House.\n",
      "\"I can tell you that the president has a great deal of respect for acting Defense Secretary Shanahan, he likes him, and when the president is ready to make an announcement on that front, he certainly will,\" Sanders said.\n",
      "Shanahan ascended to the acting role in the wake of then-Secretary of Defense James Mattis' shock resignation in December.\n",
      "In his resignation letter, Mattis said that disagreements with the president about America's treatment of both allies and strategic competitors came from beliefs that \"are strongly held and informed by over four decades of immersion in these issues.\"\n",
      "Mattis, a revered Marine with a military career spanning four decades, was known for his battlefield prowess and kinship with rank-and-file service members. Before he became Trump's Defense secretary, the four-star general led the U.S. Central Command, the combatant command responsible for the wars in Iraq and Afghanistan.\n",
      "James Mattis, U.S. Secretary of Defense, right, and Patrick Shanahan, Deputy Secretary of Defense, wait outside the Pentagon before an event in Washington, D.C., on Thursday, Aug. 9, 2018. More In contrast, Shanahan comes to the role with no experience either in the military or in foreign policy, except for his work in the Trump administration. What views he does have on America's role in the world have been shaped by his decades in the private sector.\n",
      "Before coming to the Pentagon, Shanahan spent just over 30 years at Boeing, where he helped develop the 787 Dreamliner. In 2017, he left the aerospace giant to become the 33rd deputy secretary of Defense, a role that oversees the Pentagon's colossal $700 billion budget.\n",
      "Shanahan's entrance into the Pentagon comes as Trump has pulled the United States back from global commitments and pushed forward on ambitious projects like the denuclearization of North Korea, unsettling allies as well as experts, and raising the specter of a new international balance of power.\n",
      "The Pentagon did not immediately respond to CNBC's request for comment.|0.5221765483881303|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_df  = sqlContext.createDataFrame(sim_rdd).\\\n",
    "                   withColumnRenamed('_1', 'name').\\\n",
    "                   withColumnRenamed('_2', 'similarity').\\\n",
    "                   orderBy(\"similarity\", ascending = False)\n",
    "sim_df.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
