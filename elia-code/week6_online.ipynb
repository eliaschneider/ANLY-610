{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visit http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "* Read about word2vec and download the Google pre-trained model binary\n",
    "\n",
    "**Required**:\n",
    "\n",
    "* For any selected title in your Webhose dataset (of size 10000), write a Python program than calculates 100 most similar titles from the remaining 9999:\n",
    "    * Calculate pairwise similarity using word2vec model\n",
    "    * Sort in reverse order to determine 100 titles with highest scores\n",
    "    * Print the selected title and those 100 similar titles\n",
    "* Review information about Apache Spark here\n",
    "* Review and download DataBricks Word2Vec Spark Training notebook here\n",
    "* Train word2vec model, based on the texts of the articles in your Webhose dataset, using Spark Word2Vec function\n",
    "\n",
    "Submission should consist of Jupyter Notebook file along with output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Google pre-trained model binary Word2vec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import gensim, operator\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_path = '/home/elia/Dropbox/Harrisburg/ANLY_610/codes/models/wordvec/'\n",
    "data_path = '/home/elia/Dropbox/Harrisburg/ANLY_610/codes/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec model...\n",
      "Finished loading Word2Vec model...\n"
     ]
    }
   ],
   "source": [
    "def load_wordvec_model(modelName, modelFile, flagBin):\n",
    "    print('Loading ' + modelName + ' model...')\n",
    "    model = KeyedVectors.load_word2vec_format(model_path + modelFile, binary=flagBin)\n",
    "    print('Finished loading ' + modelName + ' model...')\n",
    "    return model\n",
    "\n",
    "model_word2vec = load_wordvec_model('Word2Vec', 'GoogleNews-vectors-negative300.bin.gz', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_webhouse_data(data_name): \n",
    "    data_file = data_path + data_name + '.json'\n",
    "    with open(data_file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        return data\n",
    "    \n",
    "data = load_webhouse_data('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_similarity(input1, input2, vectors):\n",
    "    term_vectors = [np.zeros(300), np.zeros(300)]\n",
    "    terms = [input1, input2]\n",
    "        \n",
    "    for index, term in enumerate(terms):\n",
    "        for i, t in enumerate(term.split(' ')):\n",
    "            try:\n",
    "                term_vectors[index] += vectors[t]\n",
    "            except:\n",
    "                term_vectors[index] += 0\n",
    "        \n",
    "    result = (1 - spatial.distance.cosine(term_vectors[0], term_vectors[1]))\n",
    "    if result is 'nan':\n",
    "        result = 0\n",
    "        \n",
    "    return result\n",
    "\n",
    "# function checks whether the input words are present in the vocabulary for the model\n",
    "def vocab_check(vectors, words):\n",
    "    \n",
    "    output = list()\n",
    "    for word in words:\n",
    "        if word in vectors.vocab:\n",
    "            output.append(word.strip())\n",
    "            \n",
    "    return output\n",
    "\n",
    "# function calculates similarity between two strings using a particular word vector model\n",
    "def calc_similarity(input1, input2, vectors):\n",
    "    s1words = set(vocab_check(vectors, input1.split()))\n",
    "    s2words = set(vocab_check(vectors, input2.split()))\n",
    "    if len(s1words) == 0 or len(s2words) == 0:\n",
    "        return 0 \n",
    "    output = vectors.n_similarity(s1words, s2words)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 titles most similar to The Latest: President Trump signs Bibles at Alabama church\n",
      "---------------------------------------------------------------------------------------------------------\n",
      "similarity | title \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "0.9999999  | 🔥 Trump just blurted out that Michael Cohen “directly asked me for a pardon” — thereby declaring himself a fact witness and fair game for deposition. Stable Genius Strikes Again.\n",
      "0.9999999  | 🔥 Trump calls Russia investigation a ‘collusion witch hoax’ in rambling and inaccurate White House rant: he wrongly suggested the judge who sentenced Paul Manafort, to 47 months in jail had said “there was no collusion with Russia”.\n",
      "0.9999999  | 👉 Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | 👉 Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | 👉 Trump says his former lawyer and fixer Michael Cohen 'directly asked me for a pardon' via Hvper.com\n",
      "0.9999999  | “We Do Not Have Any Illusions on NKorea”\n",
      "0.9999999  | “Trump pressured aides to get security clearances for Ivanka, Kushner”\n",
      "0.9793438  | “Trump 2: People for Factories” Can’t Win an Election. So What Now? – Daily Stormer\n",
      "0.9793438  | “Scandalous” Ballot Harvesting Needs Federal Ban, Says RNC Member\n",
      "0.9793438  | “Oh My God, Right At The President!”: SUV Almost Hits Trump’s Motorcade – Real Conservatives Unite\n",
      "0.9782600  | “Lights Out!” Did Trump and His Neocons Recycle Bush-Era Plan to Knock Out Venezuela’s Power Grid?\n",
      "0.9493324  | “I have a follow-up to my colleague’s question” – finally, the White House press corps works together\n",
      "0.9493324  | “He’s Just Not Worth It” Speaker Pelosi Comes Out Against Impeaching President Trump …(For Now)\n",
      "0.9493324  | “Great Progress in China Trade Talks” Happening\n",
      "0.9493324  | “Fake Melania” Meme Is Causing The Internet To Lose Its Mind\n",
      "0.9493324  | “Democrats don’t hate Jewish people, that’s silly!” — Hack Acosta DEFENDS Democrats on anti-Semitism [VIDEO]\n",
      "0.9493324  | “China Deal Would Mean Very Big Spike for Markets”\n",
      "0.9493324  | “Andrew McCabe” – Google News: MILBANK: Trump hires only the worst people | Opinion – Lockport Union-Sun & Journal\n",
      "0.9493324  | ‘Yellow peril’: Here’s how blaming China for Fentanyl continues a racist legacy\n",
      "0.9493324  | ‘Why would you lie about that?’: Trump is telling donors the ‘Tim Apple’ flub is ‘fake news’ — despite video evidence\n",
      "0.9493324  | ‘Why would you lie about that?’: Republican donors don’t understand why Trump would lie about ‘Tim Apple’ flub\n",
      "0.9493324  | ‘We saw things that you wouldn’t believe’\n",
      "0.9493324  | ‘Unsustainable’: Here’s how Trump’s economic policies are floundering\n",
      "0.9493324  | ‘Trump just identified himself as a key witness’: How the president’s latest attack on Cohen could backfire legally\n",
      "0.9493324  | ‘Trump isn’t a vessel for God’s will’: Bill Maher destroys Evangelicals for believing the president is just like King Cyrus\n",
      "0.9493324  | ‘Trump is a cancer on the country,’ House Dem says\n",
      "0.9493324  | ‘Tim Apple’ gaffe was on purpose: Trump\n",
      "0.9493324  | ‘There’s No Reason to Obsess’ Over Budget Deficit, President Trump’s Top Economic Adviser Says\n",
      "0.9493324  | ‘The Supreme Court disagrees’: Trump gets wrecked for saying border wall’s ‘constitutionality’ doesn’t matter\n",
      "0.9493324  | ‘The ISIS threat will remain,’ John Bolton says\n",
      "0.9493324  | ‘The Daily Show’ as a news source?\n",
      "0.9493324  | ‘Socialism!’ is the GOP rallying cry for 2020\n",
      "0.9493324  | ‘Shadow Media’s’ Dark Money Funded $2 Million To ‘Investigate’ Donald Trump\n",
      "0.9493324  | ‘Saturday Night Live’ Ratings Slip With Host Idris Elba\n",
      "0.9493324  | ‘Saturday Night Live' takes on R. Kelly in cold open, giving Trump jokes a brief rest\n",
      "0.9493324  | ‘SNL’s’ Pete Davidson on Michael Jackson and R. Kelly: ‘You Just Have to Admit They’re Bad People’\n",
      "0.9493324  | ‘S.N.L.’: Idris Elba Hosts, and R. Kelly Gets Roasted - The New York Times\n",
      "0.9436951  | ‘S.N.L.’: Idris Elba Hosts, and R. Kelly Gets Roasted\n",
      "0.9115126  | ‘Rub and Tug’: Woman Who Sold Access to Trump and Family Ran Florida Sex Spas\n",
      "0.8983159  | ‘Repugnant’: MSNBC’s Nicolle Wallace and panelists explain how Fox News ‘instructs’ Trump\n",
      "0.8780873  | ‘President Trump tweeted about my football skills’\n",
      "0.8727726  | ‘President Trump tweeted about my football skills’\n",
      "0.8596358  | ‘Phony WWE-style posturing’: CNN boss branded hypocrite after calling Fox News ‘propaganda network’\n",
      "0.8433072  | ‘Patently false’: Sarah Sanders gets pummeled as she struggles to defend Trump’s claim that Democrats hate Jews\n",
      "0.8433072  | ‘Not productive anymore’: GOP strategist on partisan divide\n",
      "0.8433072  | ‘Not my fault’: Trump struggles to defend his record amid setbacks on immigration, trade, North Korea\n",
      "0.8368047  | ‘My Dad’s Not a Racist’: Book Describes Ivanka Trump’s Defense After Charlottesville\n",
      "0.8368047  | ‘My Dad's Not a Racist': Book Describes Ivanka Trump's Defense After Charlottesville\n",
      "0.8368047  | ‘Miami Herald’ Reporters Investigate Ties Between Massage Parlor Owner, Trump\n",
      "0.8368047  | ‘I’m winning!’ Trump attacks ‘Wacky Nut Job’ Ann Coulter for her border wall criticism\n",
      "0.8368047  | ‘I’m winning!’ Trump attacks ‘Wacky Nut Job’ Ann Coulter for her border wall criticism\n",
      "0.8368047  | ‘I’m not for impeachment,’ Pelosi says, potentially roiling fellow Democrats\n",
      "0.8264572  | ‘I’m not for impeachment,’ Pelosi says, potentially roiling fellow Democrats\n",
      "0.8079037  | ‘It’s on videotape’: MSNBC’s Morning Joe stunned by Trump's obvious lie about ‘Tim Apple’\n",
      "0.8011519  | ‘It would ultimately come down to the use of force’: What would happen if Trump refused to leave office after 2020 loss?\n",
      "0.8011519  | ‘It would ultimately come down to the use of force’: What would happen if Trump refused to leave office after 2020 loss?\n",
      "0.8011519  | ‘It has been proven’: Fox News host burns GOPer for claiming there was no ‘wrongdoing’ in 2016 election\n",
      "0.8011519  | ‘It gets real personal, real fast’: Dems fear targeting Trump kids could backfire\n",
      "0.8011519  | ‘Impeach the Russian Asset’: Protesters taunt Trump with signs as he arrives at Mar-a-Lago\n",
      "0.8011519  | ‘Impeach the Russian Asset’: Protesters taunt Trump with signs as he arrives at Mar-a-Lago\n",
      "0.8011519  | ‘I'm not for impeachment,' Pelosi says, potentially roiling fellow Democrats\n",
      "0.8011519  | ‘He’s just not worth it’: Pelosi says she opposes moving to impeach Trump\n",
      "0.8011519  | ‘He’s just not worth it’: Pelosi says she opposes moving to impeach Trump\n",
      "0.8011519  | ‘Help from Trump is a phone call away’- Chamisa\n",
      "0.8011519  | ‘Help from Trump is a phone call away’- Chamisa\n",
      "0.8011519  | ‘He said, he said’ — Who can you trust in Michael Cohen-Donald Trump saga?\n",
      "0.8011519  | ‘He said, he said’ – Who can you trust in Cohen-Trump saga?\n",
      "0.8011519  | ‘He said, he said’ – Who can you trust in Cohen-Trump saga?\n",
      "0.8011519  | ‘Hanging’s too good’: Journalist explains why Dems should skip Trump impeachment — and destroy him by other means\n",
      "0.8011519  | ‘Hanging’s too good’: Journalist explains why Dems should skip Trump impeachment — and destroy him another way\n",
      "0.8011519  | ‘HAIL SATAN’: Satanists Fight Trump, & Satanic Temple Founder Says He’s Comin’ For All You Theocrats | Politics\n",
      "0.8011519  | ‘HAIL SATAN': Satanists Fight Trump, & Satanic Temple Founder Says He's Comin' For All You Theocrats\n",
      "0.8011519  | ‘Fox News’ Host Pete Hegseth Says His New Goal In Life Is To Have Donald Trump Sign His Bible\n",
      "0.8011519  | ‘Fake Melania’ conspiracy theory is back after Trumps visit Alabama\n",
      "0.7920104  | ‘Fake Melania’ Conspiracy Theory Takes Off on Twitter Again\n",
      "0.7916777  | ‘Crazy’: CNN conservative shoots down Trump’s budget GOP can’t even understand\n",
      "0.7894279  | ‘Betrayal’: Trump supporters furious with the president for backsliding on immigration policy with promises of more workers\n",
      "0.7894279  | ‘Befuddled Old Goofball’: Internet reacts to Trump’s ridiculous defense of ‘Tim Apple’ flub\n",
      "0.7894279  | ‘Befuddled Old Goofball’: Internet explodes in laughter over Trump’s ridiculous defense of ‘Tim Apple’ flub\n",
      "0.7894279  | ‘Absurd’ to say U.S. President Trump unreliable trade negotiator with China: White House\n",
      "0.7894279  | ‘Absurd’ to say Trump unreliable trade negotiator with China: White House\n",
      "0.7894279  | ‘Absurd’ to say Trump unreliable trade negotiator with China: White House\n",
      "0.7883771  | ‘Absurd’ to say Trump unreliable trade negotiator with China: White House\n",
      "0.7724894  | ‘Absurd’ to say Trump unreliable trade negotiator with China – White House\n",
      "0.7689173  | ‘About as likely as Mexico paying for Trump’s wall’: Some experts say Elizabeth Warren’s plan to break up Big Tech will never happen\n",
      "0.7657953  | ‘About as likely as Mexico paying for Trump’s wall’: Some experts say Elizabeth Warren’s plan to break up Big Tech will never happen\n",
      "0.7565801  | ‘About as likely as Mexico paying for Trump’s wall’: Some experts say Elizabeth Warren’s plan to break up Big Tech will never happen\n",
      "0.7514790  | ‘About as likely as Mexico paying for Trump’s wall’: Some experts say Elizabeth Warren’s plan to break up Big Tech will never happen\n",
      "0.7486728  | Σουηδία: Έκρηξη σε άδειο λεωφορείο στο κέντρο της Στοκχόλμης - [Capital.gr]\n",
      "0.7486728  | Πλήρωσε την μαφία για να σκοτώσουν τον ερωμένο της - Τον \"τσιμέντωσαν\" - [Pronews.gr]\n",
      "0.7439390  | Να γιατί αυτό το μέρος ονομάζεται \"πισίνα του θανάτου\" - [E-eidhseis.com]\n",
      "0.7439390  | Μεγάλη έκρηξη στη Στοκχόλμη! Πυκνοί καπνοί καλύπτουν την πόλη! - [Newsit.gr]\n",
      "0.7402664  | đ¤đ¤đ¤đ¤đ¤đ¤đ¤đ¤đ¤đ¤đ¤ – Daily Stormer\n",
      "0.7353255  | trump budget discussion thread\n",
      "0.7202483  | storybreak stars\n",
      "0.7199541  | slams 'grandstanding' California governor on asylum shelters\n",
      "0.7199541  | pricey telling Trump\n",
      "0.7198457  | pre-order the Mueller Report @ Amazon\n",
      "0.7194962  | popcorn futures soar\n",
      "0.7191714  | political opinion of the day\n"
     ]
    }
   ],
   "source": [
    "def get_most_similar_titles(data, data_id, sim_tit_num=100): \n",
    "    if data_id >= len(data): \n",
    "        raise IOError('The id to select title should be between 0 and {}'.format(len(data)))\n",
    "    title = data[data_id]['title']        \n",
    "    comparison_matrix = np.array(\n",
    "        [[data[index]['title'], calc_similarity(title, data[index]['title'], model_word2vec)] \n",
    "         for index in range(len(data)) if index != data_id])\n",
    "    return np.sort(comparison_matrix, axis=0)[::-1][:100]\n",
    "\n",
    "title_id = 23\n",
    "print(\"100 titles most similar to {}\".format(data[title_id]['title']))\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "print(\"similarity | title \")\n",
    "print(\"---------------------------------------------------------------------------------------------------------\")\n",
    "for line in get_most_similar_titles(data, title_id): \n",
    "    print(\"{0:.7f}\".format(float(line[1])) + \"  | {}\".format(str(line[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **pyspark section**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = '/usr/bin/python3'\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext() \n",
    "config = sc.getConf()\n",
    "config.set('spark.cores.max','4')\n",
    "config.set('spark.executor.memory', '4G')\n",
    "config.set('spark.driver.maxResultSize', '4g')\n",
    "config.set('spark.serializer', 'org.apache.spark.serializer.KryoSerializer')\n",
    "config.set('spark.kryoserializer.buffer.max', '256m')\n",
    "config.set(\"spark.driver.cores\", \"3\")\n",
    "\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext(conf = config) \n",
    "sqlContext = SQLContext(sc)\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, Word2Vec\n",
    "\n",
    "print(\"Using Apache Spark Version\", sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def cleanup_pretokenize(text):\n",
    "    #text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.replace(\"'s\", \" \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.replace(\"'ve\", \" have \")\n",
    "    text = text.replace(\"'re\", \" are \")\n",
    "    text = text.replace(\"I'm\",\" I am \")\n",
    "    text = text.replace(\"you're\",\" you are \")\n",
    "    text = text.replace(\"You're\",\" You are \")\n",
    "    text = text.replace(\"-\",\" \")\n",
    "    text = text.replace(\"/\",\" \")\n",
    "    text = text.replace(\"(\",\" \")\n",
    "    text = text.replace(\")\",\" \")\n",
    "    text = text.replace(\"%\",\" percent \")\n",
    "    return text\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "def text_cleanup(row):\n",
    "    desc = row[2].strip().lower()\n",
    "    #tokens = [w.lemma_ for w in nlp(cleanup_pretokenize(desc))]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if len(token) > 3]\n",
    "    tokens = [lmtzr.lemmatize(token,'v') for token in tokens]\n",
    "    row[2] = ' '.join(tokens)\n",
    "    return row\n",
    "\n",
    "regexTokenizer = RegexTokenizer(gaps = False, pattern = '\\w+', inputCol = 'text', outputCol = 'tokens')\n",
    "swr = StopWordsRemover(inputCol = 'tokens', outputCol = 'tokens_sw_removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author: string (nullable = true)\n",
      " |-- crawled: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- locations: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |    |-- organizations: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |    |-- persons: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- sentiment: string (nullable = true)\n",
      " |-- external_links: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- highlightText: string (nullable = true)\n",
      " |-- highlightTitle: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- ord_in_thread: long (nullable = true)\n",
      " |-- published: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- thread: struct (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- domain_rank: long (nullable = true)\n",
      " |    |-- main_image: string (nullable = true)\n",
      " |    |-- participants_count: long (nullable = true)\n",
      " |    |-- performance_score: long (nullable = true)\n",
      " |    |-- published: string (nullable = true)\n",
      " |    |-- replies_count: long (nullable = true)\n",
      " |    |-- section_title: string (nullable = true)\n",
      " |    |-- site: string (nullable = true)\n",
      " |    |-- site_categories: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- site_full: string (nullable = true)\n",
      " |    |-- site_section: string (nullable = true)\n",
      " |    |-- site_type: string (nullable = true)\n",
      " |    |-- social: struct (nullable = true)\n",
      " |    |    |-- facebook: struct (nullable = true)\n",
      " |    |    |    |-- comments: long (nullable = true)\n",
      " |    |    |    |-- likes: long (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- gplus: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- linkedin: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- pinterest: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- stumbledupon: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |    |-- vk: struct (nullable = true)\n",
      " |    |    |    |-- shares: long (nullable = true)\n",
      " |    |-- spam_score: double (nullable = true)\n",
      " |    |-- title: string (nullable = true)\n",
      " |    |-- title_full: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- uuid: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- uuid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load json \n",
    "def load_json_data(data_name): \n",
    "    data_file = data_path + data_name + '.json'\n",
    "    return sqlContext.read.json(data_file)\n",
    "\n",
    "data_df = load_json_data('trump')\n",
    "data_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|WASHINGTON (AP) -...|\n",
      "|Trump surveys Ala...|\n",
      "|The Beat with Ari...|\n",
      "|BEAUREGARD, Ala. ...|\n",
      "|Trump should reco...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|                text|              tokens|\n",
      "+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[washington, ap, ...|\n",
      "|Trump surveys Ala...|[trump, surveys, ...|\n",
      "|The Beat with Ari...|[the, beat, with,...|\n",
      "|BEAUREGARD, Ala. ...|[beauregard, ala,...|\n",
      "|Trump should reco...|[trump, should, r...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                text|              tokens|   tokens_sw_removed|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[washington, ap, ...|[washington, ap, ...|\n",
      "|Trump surveys Ala...|[trump, surveys, ...|[trump, surveys, ...|\n",
      "|The Beat with Ari...|[the, beat, with,...|[beat, ari, john,...|\n",
      "|BEAUREGARD, Ala. ...|[beauregard, ala,...|[beauregard, ala,...|\n",
      "|Trump should reco...|[trump, should, r...|[trump, reconside...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_df = data_df.select('text')\n",
    "text_df.show(5)\n",
    "df_tokens = regexTokenizer.transform(text_df)\n",
    "df_tokens.show(5)\n",
    "desc_swr = swr.transform(df_tokens)\n",
    "desc_swr.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(vectorSize = 300, minCount = 5, inputCol = 'tokens_sw_removed', outputCol = 'wordvectors')\n",
    "model = word2vec.fit(desc_swr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|         wordvectors|\n",
      "+--------------------+--------------------+\n",
      "|WASHINGTON (AP) -...|[-0.0749518844910...|\n",
      "|Trump surveys Ala...|[-0.0200785594274...|\n",
      "|The Beat with Ari...|[-0.1803129903661...|\n",
      "|BEAUREGARD, Ala. ...|[-0.0259655292435...|\n",
      "|Trump should reco...|[-0.0499572096919...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordvectors = model.transform(desc_swr)\n",
    "text_desc = wordvectors.select('text','wordvectors')\n",
    "text_desc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+\n",
      "|        word|         similarity|\n",
      "+------------+-------------------+\n",
      "|        mike| 0.5678425431251526|\n",
      "|  emphasised| 0.5327044725418091|\n",
      "|     hawkish| 0.4932403564453125|\n",
      "|     gokhale|0.47736334800720215|\n",
      "|      bolton|0.47003406286239624|\n",
      "|      echoed|0.45853370428085327|\n",
      "|       vijay| 0.4505883753299713|\n",
      "|     advisor| 0.4262145161628723|\n",
      "|   secretary| 0.4251237213611603|\n",
      "|      mullen|0.40693843364715576|\n",
      "|counterparts|0.40623241662979126|\n",
      "|  undermined|0.38990429043769836|\n",
      "|      scored| 0.3882525563240051|\n",
      "|  emphasized| 0.3881252706050873|\n",
      "|      yaqing| 0.3880544602870941|\n",
      "|     qureshi| 0.3836938738822937|\n",
      "|      biegun|  0.380886971950531|\n",
      "|        hale| 0.3719295263290405|\n",
      "|       pence|0.37069055438041687|\n",
      "| embarrassed|0.36694759130477905|\n",
      "+------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "synonyms = model.findSynonyms(\"pompeo\", 20)   \n",
    "synonyms.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|index|                text|              tokens|   tokens_sw_removed|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    1|secretary of ener...|[secretary, of, e...|[secretary, energ...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEARCH_QUERY = \"secretary of energy in the Trump administration\"\n",
    "query_df  = sc.parallelize([(1,SEARCH_QUERY)]).toDF(['index', 'text'])\n",
    "query_tok = regexTokenizer.transform(query_df)\n",
    "query_swr = swr.transform(query_tok)\n",
    "query_swr.show()\n",
    "query_vec = model.transform(query_swr)\n",
    "query_vec = query_vec.select('wordvectors').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / (np.sqrt(np.dot(v2, v2))+.1)\n",
    "chunk = text_desc.collect()\n",
    "sim_rdd = sc.parallelize((i[0], float(cossim(query_vec, i[1]))) for i in chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "|name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |similarity        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "|Murkowski Welcomes Intent to Nominate David Bernhardt to be Interior Secretary\n",
      "U.S. Sen. today issued the following statement after President Trump announced his intent to nominate David Bernhardt to be Secretary of the Department of the Interior (DOI).\n",
      "“I strongly support David Bernhardt to serve as Secretary of the Interior. He is an excellent choice and has demonstrated he is more than capable of leading on a permanent basis. It is critical that our Interior Secretary understand Alaska and I have no doubt he will continue to be a strong partner for our state. I will schedule a hearing and seek to move his nomination forward as expeditiously as possible.”\n",
      "Bernhardt has served as Acting Interior Secretary since January 2019. On July 24, 2017, the Senate confirmed Bernhardt to serve as deputy secretary of DOI with bipartisan support.\n",
      "Murkowski is Resources.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |0.538481548614037 |\n",
      "|Defense Department's Patrick Shanahan, before he was tapped by President Donald Trump to serve as the department's Acting Secretary More WASHINGTON — The White House declined to comment Monday on whether acting Secretary of Defense Patrick Shanahan would be tapped later this week by President Donald Trump to take the top spot at the Pentagon.\n",
      "\"I'm not going to make any personnel announcements at this time,\" press secretary Sarah Huckabee Sanders told reporters Monday during a media briefing at the White House.\n",
      "\"I can tell you that the president has a great deal of respect for acting Defense Secretary Shanahan, he likes him, and when the president is ready to make an announcement on that front, he certainly will,\" Sanders said.\n",
      "Shanahan ascended to the acting role in the wake of then-Secretary of Defense James Mattis' shock resignation in December.\n",
      "In his resignation letter, Mattis said that disagreements with the president about America's treatment of both allies and strategic competitors came from beliefs that \"are strongly held and informed by over four decades of immersion in these issues.\"\n",
      "Mattis, a revered Marine with a military career spanning four decades, was known for his battlefield prowess and kinship with rank-and-file service members. Before he became Trump's Defense secretary, the four-star general led the U.S. Central Command, the combatant command responsible for the wars in Iraq and Afghanistan.\n",
      "James Mattis, U.S. Secretary of Defense, right, and Patrick Shanahan, Deputy Secretary of Defense, wait outside the Pentagon before an event in Washington, D.C., on Thursday, Aug. 9, 2018. More In contrast, Shanahan comes to the role with no experience either in the military or in foreign policy, except for his work in the Trump administration. What views he does have on America's role in the world have been shaped by his decades in the private sector.\n",
      "Before coming to the Pentagon, Shanahan spent just over 30 years at Boeing, where he helped develop the 787 Dreamliner. In 2017, he left the aerospace giant to become the 33rd deputy secretary of Defense, a role that oversees the Pentagon's colossal $700 billion budget.\n",
      "Shanahan's entrance into the Pentagon comes as Trump has pulled the United States back from global commitments and pushed forward on ambitious projects like the denuclearization of North Korea, unsettling allies as well as experts, and raising the specter of a new international balance of power.\n",
      "The Pentagon did not immediately respond to CNBC's request for comment.|0.5221765483881303|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim_df  = sqlContext.createDataFrame(sim_rdd).\\\n",
    "                   withColumnRenamed('_1', 'name').\\\n",
    "                   withColumnRenamed('_2', 'similarity').\\\n",
    "                   orderBy(\"similarity\", ascending = False)\n",
    "sim_df.show(2, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
