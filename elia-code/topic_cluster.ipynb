{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import ldamodel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "data_path = '../data/'\n",
    "model_path = '../model/'\n",
    "\n",
    "def load_webhouse_data(data_name): \n",
    "    data_file = data_path + data_name + '.json'\n",
    "    with open(data_file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        return data\n",
    "\n",
    "def cleanup_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = text.replace(\"'s\", \" \")\n",
    "    text = text.replace(\"n't\", \" not \")\n",
    "    text = text.replace(\"'ve\", \" have \")\n",
    "    text = text.replace(\"'re\", \" are \")\n",
    "    text = text.replace(\"I'm\",\" I am \")\n",
    "    text = text.replace(\"you're\",\" you are \")\n",
    "    text = text.replace(\"You're\",\" You are \")\n",
    "    text = text.replace(\"-\",\" \")\n",
    "    text = text.replace(\"/\",\" \")\n",
    "    text = text.replace(\"(\",\" \")\n",
    "    text = text.replace(\")\",\" \")\n",
    "    text = text.replace(\"%\",\" percent \")\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    text = \" \".join([i for i in text.lower().split() if i not in stopwords])\n",
    "    token = [WordNetLemmatizer().lemmatize(i) for i in text.split()]\n",
    "    return token\n",
    "    \n",
    "# data = load_webhouse_data('microsoft')\n",
    "data = load_webhouse_data('microsoft_0419_0519_clean') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [[data[i]['title'], data[i]['published'][:10]]  for i in range(len(data))]\n",
    "df_feeds = pd.DataFrame(titles,columns=['title', 'date'])\n",
    "titles = df_feeds[['title']].applymap(cleanup_text)['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(titles)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.8)\n",
    "corpora = [dictionary.doc2bow(doc) for doc in titles]\n",
    "\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "lda_model = ldamodel.LdaModel(corpora, num_topics=8, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
